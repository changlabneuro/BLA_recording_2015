---
title: "Supplementary Information: Models"
author: "Steve Chang et al."
date: "10/20/2015"
output: 
  pdf_document:
    fig_caption: yes        
---

# Hierarchical models for spike counts

## Model

Here, we model spike counts in the time window of interest as drawn from a Poisson distribution:
$$
\begin{aligned}
  N_i &\sim \mathrm{Poisson}(\lambda_i) \\
  \log \lambda_i &= \beta_{0 cou} + \beta_{1cou} R_i \\
  \beta_{\cdot \cdot u} &\sim \text{Multivariate-t}(\nu, \mu, \Sigma) \\
  \mu &\sim \mathrm{Normal}(0, 2) \\
  \Sigma &= (TL)(TL)^\top \\
  T &= \mathrm{diag}(\tau) \\
  \tau_j &\sim \mathrm{Cauchy}_+(0, 2.5) \\
  L &\sim \mathrm{LKJCorr}(2) \\
  \nu &\sim \mathrm{Cauchy}_+(0, 25) \\
\end{aligned}
$$
with $N_i$ the spike count on trial $i$; $c(i)$, $o(i)$, and $u(i)$ the cuing (free choice vs cued), 
outcome (neither, other, both, self), and unit for that trial; and $R_i$ the reward on the trial 
(coded as a percent of maximum).

More specifically:

- Regression coefficients for each unit are drawn from a multivariate $t$ distribution with mean $\mu$ and 
covariance $\Sigma$. We use a $t$ distribution both because the empirical distribution of coefficients is 
leptokurtic (high-peaked and heavy-tailed) and because estimation using the $t$ is more robust to the 
presence of outliers.
- We use a Cholesky factorization for the covariance matrix, with $T$ a diagonal matrix of variable scale 
parameters and $L$ a lower triangular matrix with LKJCorr prior\footnote{cf. Section 50.1 of the Stan Manual 
v.2.8.0 and references therein.}. That is, the correlation matrix $C = LL^\top$.
- For the degrees of freedom $\nu$ and scales $\tau_j$, we use weakly informative half-Cauchy (restricted to the 
positive half plane) priors.

Given this model, we are particularly interested in inferring $\mu$ and $\Sigma$, the mean and covariance of the
population of cells from which our experimental sample was drawn.

## Results

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(rstan)
source("helpers.R")

# load original data
load("data/countdata")

# load model samples
fname <- "fitobj_targacq_multi_t_cued"
load(fname)

# calculate some useful quantities
U <- length(unique(countdata$unit))
P <- dim(X)[2]

# names for plotting
vnames <- colnames(X)
vnames <- gsub(':', '.', vnames)
vnames <- gsub('outcome', '', vnames)
vnames <- gsub('reward', 's', vnames)
vnames <- gsub('cued', '', vnames)

# get point estimates of betas
fit_summary <- summary(fit, pars='beta')[[1]]
pt_betas <- fit_summary[,6]  # medians
dim(pt_betas) <- c(P, U)
pt_betas <- as.data.frame(t(pt_betas))
names(pt_betas) <- vnames

# get samples from posterior for beta
genbeta <- as.data.frame(rstan::extract(fit, pars="genbeta")[[1]])
names(genbeta) <- vnames

# get samples of posterior variance
varsamples <- data.frame(v=rstan::extract(fit, pars='Sigma')[[1]])
```
Figures blah blah, bhal

```{r, dev='pdf', echo=FALSE, fig.width=8, fig.height=6, fig.cap="Correlations between sensitivities to distinct outcomes (Choice)."}
p <- pairplot(as.data.frame(pt_betas), genbeta, varsamples, seq(9, 12))
p
```

```{r, dev='pdf', echo=FALSE, fig.keep="last", fig.width=8, fig.height=6, fig.cap="Correlations between sensitivities to distinct outcomes (Cued)."}
p <- pairplot(as.data.frame(pt_betas), genbeta, varsamples, seq(13, 16))
p

# change labels
g <- grid.ls(print=FALSE)
idx <- g$name[grep("text", g$name)]
for(i in 1:length(idx)) {
  if (i <= length(idx)/2)
    grid.edit(gPath(idx[i]), vjust=-.5)
  else
    grid.edit(gPath(idx[i]), vjust=1.5)
}
```

```{r, dev='pdf', echo=FALSE, fig.width=8, fig.height=6, fig.cap="Correlations between sensitivities (all trial types)."}
p <- pairplot(as.data.frame(pt_betas), genbeta, varsamples, seq(9, 16))
p
```

# To do:
- ~~effects of cuing in model~~
- ~~density plot of posteriors with units on top (via generated quantities in stan?)~~
- are the same cells outliers in successive time periods?

# Further models
- model social decision as a function of spike counts 
    - ~~use glmnet for prediction~~
    - use Vehtari and Gelman paper for calculating expected log likelihood (or posterior) of heldout data in stan
- quantify OT effects
    - on choice
    - on gaze

# Bullpen
- non-additive trial type effects (cued vs choice treated as unrelated?)
- ~~negative binomial or added gaussian in linear predictor~~ seems unnecessary given low spike counts
- model of separate subpopulations:
    - three groups:
        - negative tuning
        - positive tuning
        - noise (with mean constrained to 0 and perhaps diagonal $\Sigma$?; isotropic, even?)

